{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epqx-zo040z6",
        "outputId": "deda8052-f22a-4000-dbc1-b38b1d361fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import timeit\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "!pip install catboost\n",
        "!pip install scikit-learn\n",
        "\n",
        "!pip install scikit-plot\n",
        "\n",
        "from scikitplot.metrics import plot_confusion_matrix\n",
        "\n",
        "import catboost as cb\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "# from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, zero_one_loss\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from termcolor import colored\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(100)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_root = '/content/drive/My Drive/uva1/nslkdd'\n",
        "\n",
        "train_file = os.path.join(dataset_root, 'KDDTrain+.txt')\n",
        "test_file = os.path.join(dataset_root, 'KDDTest+.txt')\n",
        "\n",
        "# Original KDD dataset feature names obtained from\n",
        "# http://kdd.ics.uci.edu/databases/kddcup99/kddcup.names\n",
        "# http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
        "\n",
        "header_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
        "                'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted',\n",
        "                'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
        "                'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
        "                'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
        "                'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "                'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack_type',\n",
        "                'success_pred']"
      ],
      "metadata": {
        "id": "mFZumaaj6-Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93c1cdc-fe8e-4a08-8bba-51ce39b3612b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Differentiating between nominal, binary, and numeric features\n",
        "\n",
        "# root_shell is marked as a continuous feature in the kddcup.names\n",
        "# file, but it is supposed to be a binary feature according to the\n",
        "# dataset documentation\n",
        "\n",
        "col_names = np.array(header_names)\n",
        "\n",
        "nominal_idx = [1, 2, 3]\n",
        "binary_idx = [6, 11, 13, 14, 20, 21]\n",
        "numeric_idx = list(set(range(41)).difference(nominal_idx).difference(binary_idx))\n",
        "\n",
        "nominal_cols = col_names[nominal_idx].tolist()\n",
        "binary_cols = col_names[binary_idx].tolist()\n",
        "numeric_cols = col_names[numeric_idx].tolist()"
      ],
      "metadata": {
        "id": "w-76Pm478ZL5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_attack_types.txt maps each of the 22 different attacks to 1 of 4 categories\n",
        "# file obtained from http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types\n",
        "\n",
        "\n",
        "category = defaultdict(list)\n",
        "category['benign'].append('normal')\n",
        "\n",
        "with open('/content/drive/My Drive/uva1/nslkdd/training_attack_types.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        attack, cat = line.strip().split(' ')\n",
        "        category[cat].append(attack)\n",
        "\n",
        "attack_mapping = dict((v, k) for k in category for v in category[k])\n",
        "\n",
        "train_df = pd.read_csv(train_file, names=header_names)\n",
        "\n",
        "train_df['attack_category'] = train_df['attack_type'] \\\n",
        "    .map(lambda x: attack_mapping[x])\n",
        "train_df.drop(['success_pred'], axis=1, inplace=True)\n",
        "\n",
        "test_df = pd.read_csv(test_file, names=header_names)\n",
        "test_df['attack_category'] = test_df['attack_type'] \\\n",
        "    .map(lambda x: attack_mapping[x])\n",
        "test_df.drop(['success_pred'], axis=1, inplace=True)\n",
        "\n",
        "train_attack_types = train_df['attack_type'].value_counts()\n",
        "train_attack_cats = train_df['attack_category'].value_counts()\n",
        "\n",
        "test_attack_types = test_df['attack_type'].value_counts()\n",
        "test_attack_cats = test_df['attack_category'].value_counts()\n",
        "\n",
        "train_attack_types.plot(kind='barh', figsize=(20, 10), fontsize=20)\n",
        "\n",
        "train_attack_cats.plot(kind='barh', figsize=(20, 10), fontsize=30)\n",
        "\n",
        "test_attack_types.plot(kind='barh', figsize=(20, 10), fontsize=15)\n",
        "\n",
        "test_attack_cats.plot(kind='barh', figsize=(20, 10), fontsize=30)"
      ],
      "metadata": {
        "id": "kpKnil7N8l8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "f2ab7063-efcb-4f29-8867-d2a298969b89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='attack_category'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the binary features\n",
        "# By definition, all of these features should have a min of 0.0 and a max of 1.0\n",
        "# execute the commands in console\n",
        "\n",
        "train_df[binary_cols].describe().transpose()\n",
        "\n",
        "# Wait a minute... the su_attempted column has a max value of 2.0?\n",
        "\n",
        "train_df.groupby(['su_attempted']).size()\n",
        "\n",
        "# Let's fix this discrepancy and assume that su_attempted=2 -> su_attempted=0\n",
        "\n",
        "train_df['su_attempted'].replace(2, 0, inplace=True)\n",
        "test_df['su_attempted'].replace(2, 0, inplace=True)\n",
        "train_df.groupby(['su_attempted']).size()\n",
        "# Next, we notice that the num_outbound_cmds column only takes on one value!\n",
        "print(train_df.columns)\n",
        "\n",
        "\n",
        "# train_df.groupby(['num_outbound_cmds']).size()\n",
        "\n",
        "# # Now, that's not a very useful feature - let's drop it from the dataset\n",
        "\n",
        "# train_df.drop('num_outbound_cmds', axis=1, inplace=True)\n",
        "# test_df.drop('num_outbound_cmds', axis=1, inplace=True)\n",
        "# numeric_cols.remove('num_outbound_cmds')\n"
      ],
      "metadata": {
        "id": "p25TZIAc8xYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4cdfd6-f2b7-40f6-fb1e-b735240c1c21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
            "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
            "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
            "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
            "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
            "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
            "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
            "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
            "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
            "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
            "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
            "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
            "       'dst_host_srv_rerror_rate', 'attack_type', 'attack_category'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data Preparation\n",
        "\n",
        "\"\"\"\n",
        "train_Y = train_df['attack_category']\n",
        "train_x_raw = train_df.drop(['attack_category', 'attack_type'], axis=1)\n",
        "test_Y = test_df['attack_category']\n",
        "test_x_raw = test_df.drop(['attack_category', 'attack_type'], axis=1)\n",
        "\n",
        "'''# feature selection\n",
        "def select_features(X_train, y_train, X_test):\n",
        "    fs = SelectKBest(score_func=mutual_info_classif, k=30)\n",
        "    fs.fit(X_train, y_train)\n",
        "    X_train_fs = fs.transform(X_train)\n",
        "    X_test_fs = fs.transform(X_test)\n",
        "    return X_train_fs, X_test_fs\n",
        "'''\n",
        "\n",
        "combined_df_raw = pd.concat([train_x_raw, test_x_raw])\n",
        "combined_df = pd.get_dummies(combined_df_raw, columns=nominal_cols, drop_first=True)\n",
        "\n",
        "train_x = combined_df[:len(train_x_raw)]\n",
        "test_x = combined_df[len(train_x_raw):]\n",
        "\n",
        "# use this for catboost\n",
        "x_train = train_x_raw\n",
        "x_test = test_x_raw\n",
        "\n",
        "# Store dummy variable feature names\n",
        "dummy_variables = list(set(train_x) - set(combined_df_raw))\n",
        "\n",
        "# execute the commands in console\n",
        "train_x.describe()\n",
        "train_x['duration'].describe()\n",
        "\n",
        "# Experimenting with StandardScaler on the single 'duration' feature\n",
        "durations = train_x['duration'].values.reshape(-1, 1)\n",
        "standard_scaler = StandardScaler().fit(durations)\n",
        "scaled_durations = standard_scaler.transform(durations)\n",
        "pd.Series(scaled_durations.flatten()).describe()\n",
        "\n",
        "# Experimenting with MinMaxScaler on the single 'duration' feature\n",
        "\n",
        "min_max_scaler = MinMaxScaler().fit(durations)\n",
        "min_max_scaled_durations = min_max_scaler.transform(durations)\n",
        "pd.Series(min_max_scaled_durations.flatten()).describe()\n",
        "\n",
        "# Experimenting with RobustScaler on the single 'duration' feature\n",
        "\n",
        "min_max_scaler = RobustScaler().fit(durations)\n",
        "robust_scaled_durations = min_max_scaler.transform(durations)\n",
        "pd.Series(robust_scaled_durations.flatten()).describe()\n",
        "\n",
        "# Let's proceed with StandardScaler- Apply to all the numeric columns\n",
        "\n",
        "standard_scaler = StandardScaler().fit(train_x[numeric_cols])\n",
        "\n",
        "train_x[numeric_cols] = \\\n",
        "    standard_scaler.transform(train_x[numeric_cols])\n",
        "\n",
        "test_x[numeric_cols] = \\\n",
        "    standard_scaler.transform(test_x[numeric_cols])\n",
        "\n",
        "train_x.describe()\n",
        "\n",
        "train_Y_bin = train_Y.apply(lambda x: 0 if x is 'benign' else 1)\n",
        "test_Y_bin = test_Y.apply(lambda x: 0 if x is 'benign' else 1)\n",
        "\n",
        "'''# transform the dataset\n",
        "oversample = SMOTE()\n",
        "train_x, train_Y = oversample.fit_resample(train_x, train_Y)'''"
      ],
      "metadata": {
        "id": "IPOFfmlD87Oa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f2fe78b-6908-4a07-c48b-30c0796f8040"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# transform the dataset\\noversample = SMOTE()\\ntrain_x, train_Y = oversample.fit_resample(train_x, train_Y)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "multi class classification using decision tree\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "# Decision Tree\n",
        "def decision_tree_clf():\n",
        "    print(\"------Decision Tree Classification-------\")\n",
        "\n",
        "    # build Decision Tree classifier\n",
        "    classifier = DecisionTreeClassifier(random_state=17)\n",
        "\n",
        "    # Train Classifier\n",
        "    classifier.fit(train_x, train_Y)\n",
        "\n",
        "    # predict\n",
        "    pred_y = classifier.predict(test_x)\n",
        "\n",
        "    # confusion matrix\n",
        "    results = confusion_matrix(test_Y, pred_y)\n",
        "\n",
        "    # error rate\n",
        "    error = zero_one_loss(test_Y, pred_y)\n",
        "\n",
        "    # print results\n",
        "    print(results)\n",
        "    print(error)\n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(test_Y, pred_y)\n",
        "\n",
        "    # Precision\n",
        "    precision = precision_score(test_Y, pred_y, average='weighted')\n",
        "\n",
        "    # Recall\n",
        "    recall = recall_score(test_Y, pred_y, average='weighted')\n",
        "\n",
        "    # Error Rate\n",
        "    error = zero_one_loss(test_Y, pred_y)\n",
        "\n",
        "    # Print results\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(results)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"Error Rate:\", error)\n",
        "decision_tree_clf()\n"
      ],
      "metadata": {
        "id": "r3Bv6Piq_W3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66163415-39dd-4d92-8fe5-2b945276e29d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Decision Tree Classification-------\n",
            "[[9351   59  299    2    0]\n",
            " [1417 6125   94    0    0]\n",
            " [ 735  187 1501    0    0]\n",
            " [2341    4   11  218    0]\n",
            " [ 179    0    2    6   13]]\n",
            "0.23669268985095815\n",
            "Confusion Matrix:\n",
            "[[9351   59  299    2    0]\n",
            " [1417 6125   94    0    0]\n",
            " [ 735  187 1501    0    0]\n",
            " [2341    4   11  218    0]\n",
            " [ 179    0    2    6   13]]\n",
            "Accuracy: 0.7633073101490419\n",
            "Precision: 0.8162789878429526\n",
            "Recall: 0.7633073101490419\n",
            "Error Rate: 0.23669268985095815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answers to question 4\n",
        "def data_exploration_solution():\n",
        "    print(\"*******************\")\n",
        "    print(\"Step 4: Data Exploration (Understanding the data)\")\n",
        "    print(\"*******************\")\n",
        "    print(\"1. Identify the attribute names (Header)\")\n",
        "    print(train_df.columns)\n",
        "    print(\"2. Check the length of the Train and Test dataset\")\n",
        "    print(\"length of Train dataset: \", train_df.size)\n",
        "    print(\"length of Test dataset: \", test_df.size)\n",
        "    print(\"3. Check the total number of samples that belong to each of the five classes of the training dataset.\")\n",
        "    print(train_df.groupby('attack_category')['flag'].count())\n",
        "    print(\"*******************\")\n",
        "data_exploration_solution()"
      ],
      "metadata": {
        "id": "x504crHX5LsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890a3485-00ef-40a5-9248-4bececcbd23b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************\n",
            "Step 4: Data Exploration (Understanding the data)\n",
            "*******************\n",
            "1. Identify the attribute names (Header)\n",
            "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
            "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
            "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
            "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
            "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
            "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
            "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
            "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
            "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
            "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
            "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
            "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
            "       'dst_host_srv_rerror_rate', 'attack_type', 'attack_category'],\n",
            "      dtype='object')\n",
            "2. Check the length of the Train and Test dataset\n",
            "length of Train dataset:  5416839\n",
            "length of Test dataset:  969392\n",
            "3. Check the total number of samples that belong to each of the five classes of the training dataset.\n",
            "attack_category\n",
            "benign    67343\n",
            "dos       45927\n",
            "probe     11656\n",
            "r2l         995\n",
            "u2r          52\n",
            "Name: flag, dtype: int64\n",
            "*******************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_grid_search():\n",
        "    # Creating a grid of different hyperparameters\n",
        "    grid_params = {\n",
        "        'n_estimators': [60],\n",
        "        'criterion': [\"gini\"],\n",
        "        'min_samples_split': [2, 4, 6, 10],\n",
        "        'max_depth': [20, 25, 30],\n",
        "        # 'max_leaf_nodes': [1, 5, 7, 10]\n",
        "    }\n",
        "\n",
        "    # random forest classifer\n",
        "    clf = RandomForestClassifier()\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 3 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=3)\n",
        "\n",
        "    print(\"Training the data...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(rf_best)\n",
        "\n",
        "    print(grid_object.best_score_)\n"
      ],
      "metadata": {
        "id": "dyMgdIp45Uq7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "5LAQSro58IxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "\n",
        "\n",
        "def random_forest_clf():\n",
        "    print(colored(\"------Random Forest Classification-------\", 'red'))\n",
        "    # build classifier\n",
        "    clf = RandomForestClassifier(criterion='entropy', max_depth=30, n_estimators=48, random_state=0)\n",
        "\n",
        "    # start timer\n",
        "    start_time = timeit.default_timer()\n",
        "\n",
        "    print(\"Training the Random Forest Classifier.......\")\n",
        "\n",
        "    clf = clf.fit(train_x, train_Y)\n",
        "\n",
        "    # end timer\n",
        "    print(\"The time difference is :\", timeit.default_timer() - start_time)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    '''features = clf.feature_importances_\n",
        "    feature_cols = []\n",
        "    # print feature importance\n",
        "    for i, j in enumerate(features, 1):\n",
        "        if j <= 0.0:\n",
        "            feature_cols.append(i)\n",
        "            print(i)\n",
        "    new_train_x = train_x.copy()\n",
        "    new_test_x = test_x.copy()\n",
        "\n",
        "    for k in feature_cols:\n",
        "        new_train_x.drop(new_train_x.columns[k], axis=1, inplace=True)\n",
        "        new_test_x.drop(new_test_x.columns[k], axis=1, inplace=True)\n",
        "\n",
        "    clf2 = RandomForestClassifier(n_estimators=240, random_state=0)\n",
        "    clf2 = clf2.fit(new_train_x, train_Y)'''\n",
        "\n",
        "    # predict test data\n",
        "    pred_y = clf.predict(test_x)\n",
        "\n",
        "    # analyse prediction\n",
        "    c_matrix = confusion_matrix(test_Y, pred_y)  # confusion matrix\n",
        "    error = zero_one_loss(test_Y, pred_y)  # error\n",
        "    score = accuracy_score(test_Y, pred_y)  # accuracy score\n",
        "\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, pred_y))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # plot_confusion_matrix(clf, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f', xticks_rotation='horizontal')\n",
        "    # plt.title(\"Confusion Matrix for Random Forest\")\n",
        "    plt.show()\n",
        "\n",
        "random_forest_clf()"
      ],
      "metadata": {
        "id": "88U-z9X35Y2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf2bab5-ffd1-4228-b09e-0e490d5f7000"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Random Forest Classification-------\n",
            "Training the Random Forest Classifier.......\n",
            "The time difference is : 10.676628405999963\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[9458   67  186    0    0]\n",
            " [1906 5543  187    0    0]\n",
            " [ 750  163 1510    0    0]\n",
            " [2529    0    2   41    2]\n",
            " [ 193    0    0    4    3]]\n",
            "---------------------------\n",
            "Error: 26.5658%\n",
            "Accuracy Score: 73.4342%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.64      0.97      0.77      9711\n",
            "         dos       0.96      0.73      0.83      7636\n",
            "       probe       0.80      0.62      0.70      2423\n",
            "         r2l       0.91      0.02      0.03      2574\n",
            "         u2r       0.60      0.01      0.03       200\n",
            "\n",
            "    accuracy                           0.73     22544\n",
            "   macro avg       0.78      0.47      0.47     22544\n",
            "weighted avg       0.80      0.73      0.69     22544\n",
            "\n",
            "accuracy:  [0.97394707 0.72590361 0.62319439 0.01592852 0.015     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_grid_search():\n",
        "    # parameters\n",
        "    grid_params = {\n",
        "        'n_neighbors': [2, 5, 7, 10, 12],\n",
        "        'leaf_size': [10, 20, 30, 50, 100]\n",
        "    }\n",
        "\n",
        "    # KNN classifier\n",
        "    clf = KNeighborsClassifier(n_jobs=-1)\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 3 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=10)\n",
        "\n",
        "    print(\"Training the data...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(rf_best)"
      ],
      "metadata": {
        "id": "c4Ifj8fW5hTm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_k():\n",
        "    # find value for parameter n_neighbors value between 1 to 20 where accuracy is higher\n",
        "    for i in range(1, 21):\n",
        "        # KNN classifier\n",
        "        clf_knn = KNeighborsClassifier(n_neighbors=i)\n",
        "\n",
        "        # train data\n",
        "        clf_knn = clf_knn.fit(train_x, train_Y)\n",
        "\n",
        "        # predict\n",
        "        pred_y = clf_knn.predict(test_x)\n",
        "\n",
        "        print('accuracy for k value ', i, ': ', accuracy_score(test_Y, pred_y))\n",
        "\n",
        "\n",
        "# KNN classifier\n",
        "def knn_clf():\n",
        "    print(colored(\"------KNN Classification-------\", 'red'))\n",
        "\n",
        "    # KNN classifier\n",
        "    clf_knn = KNeighborsClassifier(n_neighbors=7)  # using 7 because it has higher accuray rate\n",
        "\n",
        "    # start timer\n",
        "    starttime = timeit.default_timer()\n",
        "\n",
        "    print(\"Training the KNN Classifier.......\")\n",
        "\n",
        "    # Train model\n",
        "    clf_knn = clf_knn.fit(train_x, train_Y)\n",
        "\n",
        "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    # predict\n",
        "    pred_y = clf_knn.predict(test_x)\n",
        "\n",
        "    # analyse results\n",
        "    c_matrix = confusion_matrix(test_Y, pred_y)  # confusion matrix\n",
        "    error = zero_one_loss(test_Y, pred_y)  # error\n",
        "    score = accuracy_score(test_Y, pred_y)\n",
        "\n",
        "    # display results\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, pred_y))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # disp = plot_confusion_matrix(clf_knn, test_x, test_Y, cmap=plt.cm.Greens)\n",
        "    # plt.title(\"Confusion Matrix for k-nearest neighbors\")\n",
        "\n",
        "    # plt.show()\n",
        "knn_clf()\n"
      ],
      "metadata": {
        "id": "ST9VTX725lnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4059e3c0-fd48-4293-b3ee-96707f60b031"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------KNN Classification-------\n",
            "Training the KNN Classifier.......\n",
            "The time difference is : 0.6646426449999581\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[9443   55  210    2    1]\n",
            " [1610 5937   89    0    0]\n",
            " [ 595  180 1648    0    0]\n",
            " [2347    2   53  171    1]\n",
            " [ 105    0   85    4    6]]\n",
            "---------------------------\n",
            "Error: 23.6826%\n",
            "Accuracy Score: 76.3174%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.67      0.97      0.79      9711\n",
            "         dos       0.96      0.78      0.86      7636\n",
            "       probe       0.79      0.68      0.73      2423\n",
            "         r2l       0.97      0.07      0.12      2574\n",
            "         u2r       0.75      0.03      0.06       200\n",
            "\n",
            "    accuracy                           0.76     22544\n",
            "   macro avg       0.83      0.51      0.51     22544\n",
            "weighted avg       0.82      0.76      0.73     22544\n",
            "\n",
            "accuracy:  [0.97240243 0.77750131 0.68014858 0.06643357 0.03      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM classification\n",
        "def svc_grid_search():\n",
        "    # Creating a grid of different hyperparameters\n",
        "    grid_params = {\n",
        "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "\n",
        "    # SVC estimator\n",
        "    clf = SVC(random_state=0)\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 3 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=10)\n",
        "\n",
        "    print(\"Training the data...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(\"Best Parameters are:\\n\", rf_best)\n",
        "\n",
        "\n",
        "# SVC\n",
        "def svm_clf():\n",
        "    print(colored(\"------SVM Classification-------\", 'red'))\n",
        "    # build classifier\n",
        "    clf_svc = SVC(kernel='poly', degree=1, C=3)  # using poly for kernel\n",
        "\n",
        "    # start timer\n",
        "    starttime = timeit.default_timer()\n",
        "\n",
        "    print(\"Training the SVM Classifier.......\")\n",
        "\n",
        "    # train SVC\n",
        "    clf_svc = clf_svc.fit(train_x, train_Y)\n",
        "\n",
        "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    # predict\n",
        "    pred_y = clf_svc.predict(test_x)\n",
        "\n",
        "    # anlayse results\n",
        "    c_matrix = confusion_matrix(test_Y, pred_y)\n",
        "    error = zero_one_loss(test_Y, pred_y)\n",
        "    score = accuracy_score(test_Y, pred_y)\n",
        "\n",
        "    # display results\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, pred_y))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # disp = plot_confusion_matrix(clf_svc, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f',\n",
        "    #                              xticks_rotation='horizontal')\n",
        "    # plt.title(\"Confusion Matrix for SVM\")\n",
        "\n",
        "    # plt.show()\n",
        "svm_clf()"
      ],
      "metadata": {
        "id": "pOw0XsD15uYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3573c775-8742-4ccf-e118-1060ee457757"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------SVM Classification-------\n",
            "Training the SVM Classifier.......\n",
            "The time difference is : 185.08966406599984\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[9112  423  168    7    1]\n",
            " [1511 6112   13    0    0]\n",
            " [ 733  112 1578    0    0]\n",
            " [2299    4    2  269    0]\n",
            " [ 191    0    0    4    5]]\n",
            "---------------------------\n",
            "Error: 24.2548%\n",
            "Accuracy Score: 75.7452%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.66      0.94      0.77      9711\n",
            "         dos       0.92      0.80      0.86      7636\n",
            "       probe       0.90      0.65      0.75      2423\n",
            "         r2l       0.96      0.10      0.19      2574\n",
            "         u2r       0.83      0.03      0.05       200\n",
            "\n",
            "    accuracy                           0.76     22544\n",
            "   macro avg       0.85      0.50      0.52     22544\n",
            "weighted avg       0.81      0.76      0.73     22544\n",
            "\n",
            "accuracy:  [0.93831737 0.80041907 0.65125877 0.1045066  0.025     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic regression hyperparameter tuning\n",
        "def logistic_reg_grid_search():\n",
        "    # Creating a grid of different hyperparameters\n",
        "    grid_params = {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'max_iter': [100, 200, 300, 500, 800, 1000]\n",
        "    }\n",
        "\n",
        "    # logistic regression classifier\n",
        "    clf = LogisticRegression(random_state=0)\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 10 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=10)\n",
        "\n",
        "    print(\"Training the model...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(rf_best)"
      ],
      "metadata": {
        "id": "6uQi8x7w5zzk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "def logistic_reg_clf():\n",
        "    print(colored(\"------Logistic Regression Classification-------\", 'red', attrs='bold'))\n",
        "    # logistic regression classifier\n",
        "    clf_lr = LogisticRegression(C=1e5, random_state=0)\n",
        "\n",
        "    # start timer\n",
        "    starttime = timeit.default_timer()\n",
        "\n",
        "    print(\"Training the Logistic Regression Classifier.......\")\n",
        "\n",
        "    # train the model\n",
        "    clf_lr = clf_lr.fit(train_x, train_Y)\n",
        "\n",
        "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    # predict\n",
        "    pred_y = clf_lr.predict(test_x)\n",
        "\n",
        "    # get results\n",
        "    c_matrix = confusion_matrix(test_Y, pred_y)\n",
        "    error = zero_one_loss(test_Y, pred_y)\n",
        "    score = accuracy_score(test_Y, pred_y)\n",
        "\n",
        "    # display results\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, pred_y))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # disp = plot_confusion_matrix(clf_lr, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f',\n",
        "    #                              xticks_rotation='horizontal')\n",
        "    # plt.title(\"Confusion Matrix for Logistic Regression\")\n",
        "\n",
        "    # plt.show()\n",
        "\n",
        "logistic_reg_clf()"
      ],
      "metadata": {
        "id": "XqWC7j8g56dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11576ab8-c593-4834-e25c-d3b75027256b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Logistic Regression Classification-------\n",
            "Training the Logistic Regression Classifier.......\n",
            "The time difference is : 20.89249995499995\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[8982   93  631    2    3]\n",
            " [1560 6055   21    0    0]\n",
            " [ 484   92 1842    5    0]\n",
            " [2522    2    1   49    0]\n",
            " [ 183    3    0    2   12]]\n",
            "---------------------------\n",
            "Error: 24.8581%\n",
            "Accuracy Score: 75.1419%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.65      0.92      0.77      9711\n",
            "         dos       0.97      0.79      0.87      7636\n",
            "       probe       0.74      0.76      0.75      2423\n",
            "         r2l       0.84      0.02      0.04      2574\n",
            "         u2r       0.80      0.06      0.11       200\n",
            "\n",
            "    accuracy                           0.75     22544\n",
            "   macro avg       0.80      0.51      0.51     22544\n",
            "weighted avg       0.79      0.75      0.71     22544\n",
            "\n",
            "accuracy:  [0.92493049 0.79295443 0.76021461 0.01903652 0.06      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning for SGD\n",
        "def sgd_grid_search():\n",
        "    # Creating a grid of different hyperparameters\n",
        "    grid_params = {\n",
        "        'loss': ['hinge', 'log'],\n",
        "        'penalty': ['l2', 'l1'],\n",
        "        'max_iter': [100, 200, 300, 400, 500],\n",
        "        'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive']\n",
        "    }\n",
        "\n",
        "    # SGD classifier\n",
        "    clf = SGDClassifier(random_state=0)\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 10 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=10)\n",
        "\n",
        "    print(\"Training the model...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(rf_best)\n",
        "\n",
        "\n",
        "# SGD classification"
      ],
      "metadata": {
        "id": "jAPcH1Cs57mx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD classification\n",
        "def sgd_clf():\n",
        "    print(colored(\"------SGD Classification-------\", 'red'))\n",
        "    # build classifier\n",
        "    clf_sgd = SGDClassifier(loss=\"hinge\", penalty=\"l1\", max_iter=200, alpha=0.001, random_state=0)\n",
        "\n",
        "    # start timer\n",
        "    starttime = timeit.default_timer()\n",
        "\n",
        "    print(\"Training the SGD Classifier.......\")\n",
        "\n",
        "    # train model\n",
        "    clf_sgd = clf_sgd.fit(train_x, train_Y)\n",
        "\n",
        "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    # predict\n",
        "    pred_y = clf_sgd.predict(test_x)\n",
        "\n",
        "    c_matrix = confusion_matrix(test_Y, pred_y)\n",
        "    error = zero_one_loss(test_Y, pred_y)\n",
        "    score = accuracy_score(test_Y, pred_y)\n",
        "\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, pred_y))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # disp = plot_confusion_matrix(clf_sgd, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f',\n",
        "    #                              xticks_rotation='horizontal')\n",
        "    # plt.title(\"Confusion Matrix for SGD\")\n",
        "\n",
        "    # plt.show()\n",
        "sgd_clf()\n"
      ],
      "metadata": {
        "id": "Y7Jpge-c5-YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c612e0-d4ac-45a5-eacc-be876266e2f9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------SGD Classification-------\n",
            "Training the SGD Classifier.......\n",
            "The time difference is : 13.772806596999999\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[9462   87  162    0    0]\n",
            " [1705 5915   16    0    0]\n",
            " [ 847  126 1450    0    0]\n",
            " [2561    0    8    5    0]\n",
            " [ 199    0    1    0    0]]\n",
            "---------------------------\n",
            "Error: 25.3371%\n",
            "Accuracy Score: 74.6629%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.64      0.97      0.77      9711\n",
            "         dos       0.97      0.77      0.86      7636\n",
            "       probe       0.89      0.60      0.71      2423\n",
            "         r2l       1.00      0.00      0.00      2574\n",
            "         u2r       0.00      0.00      0.00       200\n",
            "\n",
            "    accuracy                           0.75     22544\n",
            "   macro avg       0.70      0.47      0.47     22544\n",
            "weighted avg       0.81      0.75      0.70     22544\n",
            "\n",
            "accuracy:  [0.97435897 0.77462022 0.5984317  0.0019425  0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost Grid Search\n",
        "def adaboost_grid_search():\n",
        "    # Creating a grid of different hyperparameters\n",
        "    grid_params = {\n",
        "        'n_estimators': [20, 50, 100, 200, 500, 800],\n",
        "        'learning_rate': [0.05, 0.8, 1]\n",
        "    }\n",
        "\n",
        "    # Adaboost classifier\n",
        "    clf = AdaBoostClassifier(random_state=0)\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 10 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=10)\n",
        "\n",
        "    print(\"Training the model...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model=\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(rf_best)\n",
        "\n"
      ],
      "metadata": {
        "id": "Mmev5Dqw6EXD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adaboost\n",
        "def adaboost_clf():\n",
        "    print(colored(\"------Adaboost Classification-------\", 'red'))\n",
        "    # define classifier\n",
        "    clf_abc = AdaBoostClassifier(n_estimators=15, learning_rate=1)\n",
        "\n",
        "    # time it\n",
        "    starttime = timeit.default_timer()\n",
        "\n",
        "    print(\"Training the Adaboost Classifier.......\")\n",
        "\n",
        "    # fit data\n",
        "    clf_abc.fit(train_x, train_Y)\n",
        "\n",
        "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    # predict\n",
        "    pred_y = clf_abc.predict(test_x)\n",
        "\n",
        "    # results\n",
        "    c_matrix = confusion_matrix(test_Y, pred_y)\n",
        "    error = zero_one_loss(test_Y, pred_y)\n",
        "    score = accuracy_score(test_Y, pred_y)\n",
        "\n",
        "    # display results\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, pred_y))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # disp = plot_confusion_matrix(clf_abc, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f',\n",
        "    #                              xticks_rotation='horizontal')\n",
        "    # plt.title(\"Confusion Matrix for AdaBoost\")\n",
        "\n",
        "    # plt.show()\n",
        "\n",
        "adaboost_clf()"
      ],
      "metadata": {
        "id": "mp-JNEqo6HXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68dc3913-307e-442c-ddad-2fe8e0c5e6e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Adaboost Classification-------\n",
            "Training the Adaboost Classifier.......\n",
            "The time difference is : 12.788730474999966\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[8825  555  331    0    0]\n",
            " [1444 4375 1817    0    0]\n",
            " [ 190  306 1927    0    0]\n",
            " [1937    2  635    0    0]\n",
            " [  86    0  114    0    0]]\n",
            "---------------------------\n",
            "Error: 32.9001%\n",
            "Accuracy Score: 67.0999%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.71      0.91      0.80      9711\n",
            "         dos       0.84      0.57      0.68      7636\n",
            "       probe       0.40      0.80      0.53      2423\n",
            "         r2l       0.00      0.00      0.00      2574\n",
            "         u2r       0.00      0.00      0.00       200\n",
            "\n",
            "    accuracy                           0.67     22544\n",
            "   macro avg       0.39      0.46      0.40     22544\n",
            "weighted avg       0.63      0.67      0.63     22544\n",
            "\n",
            "accuracy:  [0.90876326 0.57294395 0.79529509 0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Layer Percepton MLP\n",
        "def mlp_clf():\n",
        "    print(colored(\"------MLP Classification-------\", 'red'))\n",
        "\n",
        "    # Build classifier\n",
        "    clf_nn = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(1000, 5), max_iter=1000, random_state=1)\n",
        "\n",
        "    print(\"Training the MLP Classifier.......\")\n",
        "\n",
        "    # start timer\n",
        "    starttime = timeit.default_timer()  # start timer\n",
        "\n",
        "    # train\n",
        "    clf_nn.fit(train_x, train_Y)\n",
        "\n",
        "    print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "    print(\"Predicting test data.......\")\n",
        "\n",
        "    # predict\n",
        "    nn_pred = clf_nn.predict(test_x)\n",
        "\n",
        "    # results\n",
        "    c_matrix = confusion_matrix(test_Y, nn_pred)\n",
        "    error = zero_one_loss(test_Y, nn_pred)\n",
        "    score = accuracy_score(test_Y, nn_pred)\n",
        "\n",
        "    # display results\n",
        "    print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "    print('---------------------------')\n",
        "    print(\"Error: {:.4f}%\".format(error * 100))\n",
        "    print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "    print(classification_report(test_Y, nn_pred))\n",
        "    print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # disp = plot_confusion_matrix(clf_nn, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f',\n",
        "    #                              xticks_rotation='horizontal')\n",
        "    # plt.title(\"Confusion Matrix for Neural Network\")\n",
        "\n",
        "    # plt.show()\n",
        "mlp_clf()\n"
      ],
      "metadata": {
        "id": "hRTFrMGn6OwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32de6f26-f8d4-4cee-dc5c-983be26da3ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------MLP Classification-------\n",
            "Training the MLP Classifier.......\n",
            "The time difference is : 809.8805868090001\n",
            "Predicting test data.......\n",
            "Confusion Matrix\n",
            "---------------------------\n",
            " [[9326   56  322    4    3]\n",
            " [1224 6375   36    1    0]\n",
            " [ 680  167 1576    0    0]\n",
            " [2200    1   50  320    3]\n",
            " [ 155    0   18    4   23]]\n",
            "---------------------------\n",
            "Error: 21.8417%\n",
            "Accuracy Score: 78.1583%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.69      0.96      0.80      9711\n",
            "         dos       0.97      0.83      0.90      7636\n",
            "       probe       0.79      0.65      0.71      2423\n",
            "         r2l       0.97      0.12      0.22      2574\n",
            "         u2r       0.79      0.12      0.20       200\n",
            "\n",
            "    accuracy                           0.78     22544\n",
            "   macro avg       0.84      0.54      0.57     22544\n",
            "weighted avg       0.83      0.78      0.75     22544\n",
            "\n",
            "accuracy:  [0.96035424 0.83486118 0.65043335 0.12432012 0.115     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xgboost grid search\n",
        "def xgboost_grid_search():\n",
        "    # Creating a grid of different hyperparameters\n",
        "    grid_params = {\"learning_rate\": [0.05, 0.10, 0.2, 0.3],\n",
        "                   \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n",
        "                   \"n_estimators\": [50, 100, 200, 250, 500]\n",
        "                   }\n",
        "\n",
        "    # Adaboost classifier\n",
        "    clf = xgb.XGBClassifier()\n",
        "\n",
        "    print(\"Searching for optimal parameters..............\")\n",
        "\n",
        "    # Building a 10 fold Cross-Validated GridSearchCV object\n",
        "    grid_object = GridSearchCV(estimator=clf, param_grid=grid_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    print(\"Training the model...............\")\n",
        "\n",
        "    # Fitting the grid to the training data\n",
        "    grid_object.fit(train_x, train_Y)\n",
        "\n",
        "    # Extracting the best parameters\n",
        "    print(grid_object.best_params_)\n",
        "\n",
        "    # Extracting the best model=\n",
        "    rf_best = grid_object.best_estimator_\n",
        "    print(rf_best)\n",
        "\n",
        "    print('Best score : ', grid_object.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "r7S59Z_E6Uu3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # xgboost classifier\n",
        "# def xgboost_clf():\n",
        "#     print(colored(\"------XGBoost Classification-------\", 'red'))\n",
        "\n",
        "#     xgb_model = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "#                                   colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
        "#                                   learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
        "#                                   min_child_weight=1, missing=None, n_estimators=490, n_jobs=-1,\n",
        "#                                   nthread=None, objective='multi:softprob', random_state=0,\n",
        "#                                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n",
        "#                                   silent=None, subsample=1, verbosity=1)\n",
        "\n",
        "#     print(\"Training the XGBoost Classifier.......\")\n",
        "\n",
        "#     # start timer\n",
        "#     starttime = timeit.default_timer()  # start timer\n",
        "\n",
        "#     xgb_model.fit(train_x, train_Y)\n",
        "\n",
        "#     print(\"The time difference is :\", timeit.default_timer() - starttime)\n",
        "\n",
        "#     print(\"Predicting test data.......\")\n",
        "\n",
        "#     # print(xgb_model.feature_importances_)\n",
        "\n",
        "#     xgb_pred = xgb_model.predict(test_x)\n",
        "\n",
        "#     # plot\n",
        "#     # plot_importance(xgb_model, height=0.9)\n",
        "#     # pyplot.show()\n",
        "\n",
        "#     # Feature importance\n",
        "#     '''selector = RFE(xgb_model, 40, step=1)\n",
        "#     selector = selector.fit(train_x, train_Y)\n",
        "#     print(selector.support_)\n",
        "#     print(selector.ranking_)'''\n",
        "\n",
        "#     # results\n",
        "#     c_matrix = confusion_matrix(test_Y, xgb_pred)\n",
        "#     error = zero_one_loss(test_Y, xgb_pred)\n",
        "#     score = accuracy_score(test_Y, xgb_pred)\n",
        "\n",
        "#     # display results\n",
        "#     print('Confusion Matrix\\n---------------------------\\n', c_matrix)\n",
        "#     print('---------------------------')\n",
        "#     print(\"Error: {:.4f}%\".format(error * 100))\n",
        "#     print(\"Accuracy Score: {:.4f}%\".format(score * 100))\n",
        "#     print(classification_report(test_Y, xgb_pred))\n",
        "#     print('accuracy: ', c_matrix.diagonal() / c_matrix.sum(axis=1))\n",
        "\n",
        "#     # Plot non-normalized confusion matrix\n",
        "#     # disp = plot_confusion_matrix(xgb_model, test_x, test_Y, cmap=plt.cm.Greens, values_format='.0f',\n",
        "#     #                              xticks_rotation='horizontal')\n",
        "#     # plt.title(\"Confusion Matrix for XGBoost\")\n",
        "\n",
        "#     # plt.show()\n",
        "\n",
        "# xgboost_clf()"
      ],
      "metadata": {
        "id": "pK6Qr2ax6Yqn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5SqUCFVu5LgY"
      }
    }
  ]
}